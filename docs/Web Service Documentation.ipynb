{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service Documentation\n",
    "This notebook will cover the code used to implement and run the service. The code covered in this documentation can be found [here](https://github.com/neurodata-nomads/nomads_cloud/blob/master/service/server.py)\n",
    ".\n",
    "## Flask Routes\n",
    "The main tool we use to interface with the web is Flask. Here are the two routes we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Index Route \n",
    "        Returns index.html template (loads web form)\n",
    "'''\n",
    "\n",
    "@app.route(\"/\", methods = [\"GET\"])\n",
    "def index():\n",
    "    client = boto3.client(\"batch\")\n",
    "    return render_template(\"index.html\")\n",
    "    \n",
    "'''\n",
    "    Submit Route \n",
    "        Upon form submission, this route submits a batch computing job and redirects back to home\n",
    "'''\n",
    "@app.route(\"/submit\", methods = [\"GET\", \"POST\"])\n",
    "def submit():\n",
    "    token = request.form[\"token\"]\n",
    "    col = request.form[\"col\"]\n",
    "    exp = request.form[\"exp\"]\n",
    "    z_range = request.form[\"z_range\"].replace(\" \", \"\")\n",
    "    y_range = request.form[\"y_range\"].replace(\" \", \"\")\n",
    "    x_range = request.form[\"x_range\"].replace(\" \", \"\")\n",
    "\n",
    "    pipeline = request.form[\"pipeline\"]\n",
    "    email = request.form[\"email\"]\n",
    "    host = \"api.boss.neurodata.io\"\n",
    "    submit_job(email, pipeline, token, col, exp, z_range, y_range, x_range)\n",
    "\n",
    "\n",
    "    return redirect(url_for(\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this code should be fairly self-explainable. The index route just renders the index.html. The submit route gathers the form parameters before submitting a job based on them. Note that the following parametsrs must be recieved in order for the job to run correctly:\n",
    "1. token - BOSS API Token\n",
    "2. col - BOSS collection you are pulling from\n",
    "3. exp - BOSS experiment you are using\n",
    "4. z_range, x_range, y_range - dimmensions of data you are pulling from BOSS\n",
    "5. pipeline - pipeline to run\n",
    "6. email - email results are sent to\n",
    "\n",
    "**Important warnings about current job submission**:\n",
    "1. The Boss cannot handle pulling large cubes (>2gb) so try to limit the dimensions of your data.\n",
    "2. The token provided will be what is used to push results to the BOSS. Make sure you have the proper permissions to push to collman_nomads collection. \n",
    "3. The dimensions must be formatted as \"int, int\".\n",
    "4. The pipeline you run must be a registered pipeline on AWS. \n",
    "\n",
    "## Submit Job\n",
    "The \"submit_job()\" function is the main bulk of the service program (called in the \"/submit\" route). Since this function is very long (aka needs to be modularized), we will break it down into a few parts and explain each part below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_job(email, pipeline, token, col, exp, z_range, y_range, x_range):\n",
    "\n",
    "    try:\n",
    "        z_range_proc = list(map(int, z_range.split(\",\")))\n",
    "        y_range_proc = list(map(int, y_range.split(\",\")))\n",
    "        x_range_proc = list(map(int, x_range.split(\",\")))\n",
    "    except:\n",
    "        return Exception(\"Job not submitted, dimensions not correctly formmated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The start of the function just processes the range dimensions to check if they are two integers. An exception will be thrown and a Server 500 error will show up on the web page if this is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"_\".join([pipeline, col, exp, \"z\", str(z_range_proc[0]), str(z_range_proc[1]), \"y\", \\\n",
    "    str(y_range_proc[0]), str(y_range_proc[1]), \"x\", str(x_range_proc[0]), str(x_range_proc[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line is very important! This is the key used to label a lot of different upload results throughout the pipeline. In the service, this job_name is used to name the Batch Job name and serve as a presigned url for where the results will show up in the S3 Bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('s3')\n",
    "\n",
    "s3_bucket_exists_waiter = client.get_waiter('bucket_exists')\n",
    "\n",
    "if pipeline == \"nomads-unsupervised\":\n",
    "    bucket = client.create_bucket(Bucket=\"nomads-unsupervised-results\")\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    bucket = s3.Bucket(\"nomads-unsupervised-results\")\n",
    "    bucket.Acl().put(ACL='public-read')\n",
    "\n",
    "    url = \"https://s3.console.aws.amazon.com/s3/buckets/nomads-unsupervised-results/{}/?region=us-east-1&tab=overview\".format(job_name)\n",
    "    send_email(url, email, pipeline)\n",
    "\n",
    "if pipeline == \"nomads-classifier\":\n",
    "    bucket = client.create_bucket(Bucket=\"nomads-classifier-results\")\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    bucket = s3.Bucket(\"nomads-classifier-results\")\n",
    "    bucket.Acl().put(ACL='public-read')\n",
    "    url = \"https://s3.console.aws.amazon.com/s3/buckets/nomads-classifier-results/{}/?region=us-east-1&tab=overview\".format(job_name)\n",
    "    send_email(url, email, pipeline)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part generates the links to the S3 folder where all the results will be stored. This url is what is emailed to the user for them to check when everything is ready. You will note several things, before the pipeline is run, we first create the necessary Bucket where the results are stored. Boto3 will not do anything if the bucket is already created so having this line here is a good safety check (the same line appears when running the actual pipeline). The buckets we create are also public (read-only) to make results-sharing much easier.\n",
    "\n",
    "The url generated is formated with the job_name (the key we use to name the S3 folder where we store our results in). We resort to this URL building because Boto3 does not have a function to generate Bucket URL's and building the URLs is actually a very straightforward task.\n",
    "\n",
    "Once the URL is generated, an email is immediately sent to the user. THe URL will display nothing until the results are finished, after which the url will be populated with the pipline contents (NDVis links, predictions).\n",
    "\n",
    "This is the send_email function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENDER = 'NOMADSPipeline@gmail.com'\n",
    "PASSWORD = pickle.load(open(\"password.pkl\", \"rb\"))\n",
    "\n",
    "def send_email(url, recipient, pipeline):\n",
    "\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "      <head></head>\n",
    "      <body>\n",
    "        <p>Hi!<br>\n",
    "           Here is the <a href=\"{}\">link</a> to {} Results.\n",
    "        </p>\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\".format(url, pipeline)\n",
    "\n",
    "    msg = MIMEText(html, \"html\")\n",
    "\n",
    "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    server.starttls()\n",
    "    server.login(SENDER, PASSWORD)\n",
    "    server.sendmail(SENDER, recipient, msg.as_string())\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sending emails, we are using a standard python library called smtplib. To send emails, you need to update the SENDER and PASSWORD global variables. For security reasons, we pickle the PASSWORD and do not push it to github. \n",
    "\n",
    "The majority of the function after this is just interfacing with AWS. There's a lot of parameters to be handled and you can read more about this part in the boto3 AWS Batch documentation. We will only cover a few parts of this interfacing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    client = boto3.client(\"batch\")\n",
    "    response = client.describe_compute_environments(\n",
    "        computeEnvironments=[\n",
    "            'nomads-ce',\n",
    "        ],\n",
    "    )\n",
    "    if len(response[\"computeEnvironments\"]) == 0:\n",
    "        response = client.create_compute_environment(\n",
    "            type='MANAGED',\n",
    "            computeEnvironmentName='nomads-ce',\n",
    "            computeResources={\n",
    "                'type': 'EC2',\n",
    "                'desiredvCpus': 0,\n",
    "                'instanceRole': 'ecsInstanceRole',\n",
    "                'instanceTypes': [\n",
    "                    \"optimal\"\n",
    "                ],\n",
    "                'maxvCpus': 20,\n",
    "                'minvCpus': 0,\n",
    "                'securityGroupIds': [\n",
    "                    'sg-41927a3e',\n",
    "                ],\n",
    "                'subnets': [\n",
    "                    'subnet-11dc531d',\n",
    "                    'subnet-17c65f72',\n",
    "                    'subnet-75006549',\n",
    "                    'subnet-4e2ace06',\n",
    "                    'subnet-7ca59151',\n",
    "                    'subnet-74f3d02f'\n",
    "                ],\n",
    "                'tags': {\n",
    "                    'Name': 'Batch Instance - C4OnDemand',\n",
    "                },\n",
    "            },\n",
    "            serviceRole='AWSBatchServiceRole',\n",
    "            state='ENABLED',\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of some of the interfacing required. Here, we are create compute environments for AWS Batch. Similar steps are made to instantiate other BOSS resources as well. Some things to point out for instantiating compute environments: the \"ecsInstanceRole\" and \"AWSBatchServiceRole\" are provided roles that handle AWS permissions while the job is being run. This is how we allow the registered pipeline to push results to S3 without running into permission issues.\n",
    "\n",
    "AWS can generate the two we use here automatically. If your AWS account throws an error, log into AWS Console and make sure these roles exist.\n",
    "\n",
    "One thing we also do here that we repeat for all other Batch resources is first call a \"describe\" function. This just makes sure that we aren't making the same resources over and over again. The describe just searches to see if a \"nomads-ce\" compute environment already exists, before trying to create it. All the other parameters are explained in [AWS Batch boto3 documentation](http://boto3.readthedocs.io/en/latest/reference/services/batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.describe_job_definitions(\n",
    "        jobDefinitionName=pipeline,\n",
    "        status='ACTIVE',\n",
    "    )\n",
    "if len(response[\"jobDefinitions\"]) == 0:\n",
    "    if pipeline == \"nomads-unsupervised\":\n",
    "        register_nomads_unsupervised(client)\n",
    "    if pipeline == \"nomads-classifier\":\n",
    "        register_nomads_classifier(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the last important part of the function we will cover. This is the code to specify which job will actually be run. When you are adding new piplines, make sure to change these lines to include your pipeline. All this funciton does is register the proper job definition for your pipeline. Note the pipeline you are registering must be already in AWS as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_nomads_unsupervised(client):\n",
    "    response = client.register_job_definition(\n",
    "        type='container',\n",
    "        containerProperties={\n",
    "            'command': [\n",
    "                \"echo\",\n",
    "                \"Staring Container\"\n",
    "            ],\n",
    "            'image': '389826612951.dkr.ecr.us-east-1.amazonaws.com/nomads-unsupervised',\n",
    "            'memory': 4000,\n",
    "            'vcpus': 1,\n",
    "        },\n",
    "        jobDefinitionName=\"nomads-unsupervised\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example job definition being registered. Note that you must provide an image. This image is the dockerized pipeline that is uploaded to AWS.\n",
    "\n",
    "Finally, the actual job submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.submit_job(\n",
    "        jobName=job_name,\n",
    "        jobQueue='nomads-queue',\n",
    "        jobDefinition=pipeline,\n",
    "        containerOverrides={\n",
    "            'vcpus': 1,\n",
    "            'memory': 2000,\n",
    "            'command': [\n",
    "                \"python3\",\n",
    "                \"driver.py\",\n",
    "                \"--host\",\n",
    "                \"api.boss.neurodata.io\",\n",
    "                \"--token\",\n",
    "                token,\n",
    "                \"--col\",\n",
    "                col,\n",
    "                \"--exp\",\n",
    "                exp,\n",
    "                \"--z-range\",\n",
    "                z_range,\n",
    "                \"--x-range\",\n",
    "                x_range,\n",
    "                \"--y-range\",\n",
    "                y_range\n",
    "            ],\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one really important thing to notice here is that we call \"python3 driver.py\" as our command along with all the arguments we need to run the funtion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
